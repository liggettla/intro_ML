{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "historical.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1cIs-MoG-ppkewFq94mmM2qmhUWq6spaC",
      "authorship_tag": "ABX9TyMGm9D+r30qJsIwiNWgXrTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liggettla/intro_ML/blob/master/historical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g1J_0YAUC-7",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "[This](https://towardsdatascience.com/getting-rich-quick-with-machine-learning-and-stock-market-predictions-696802da94fe) might be a fun example to rework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJYag7oZI9Qk",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4uTd9fYwtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/Finance/turbospoon/util')\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# from util import *\n",
        "import numpy as np                  \n",
        "import pandas as pd                 \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import tree\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def pretty(size='talk'):\n",
        "    sns.set_palette('pastel')\n",
        "    sns.set_style('ticks')\n",
        "    sns.set_context(size)\n",
        "pretty()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGfMrRDVIxGM",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSfSWYGeIsXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "def historical():\n",
        "    import pandas as pd\n",
        "    import pandas_datareader as pdr\n",
        "    from pandas_datareader.robinhood import RobinhoodHistoricalReader as rhr\n",
        "\n",
        "    # holdings = pd.read_csv('../personal_data/holdings.csv')\n",
        "\n",
        "    # get historical closing data\n",
        "    # start and end do nothing for robinhood atm\n",
        "    # historical = rhr('QQQ', start='2018-12-15', end='2018-12-18').read()\n",
        "    historical = rhr('QQQ').read()\n",
        "\n",
        "    return historical\n",
        "\n",
        "# this holds daily information\n",
        "class DailyInfo:\n",
        "\n",
        "    def __init__(self, historical):\n",
        "        import pandas as pd\n",
        "\n",
        "        self.historical = historical\n",
        "        self.holdings = pd.read_csv('../personal_data/holdings.csv')\n",
        "        self.shares = float(self.holdings[self.holdings.Stock == 'QQQ'].Shares)\n",
        "\n",
        "    def pct_change(self):\n",
        "        return (100 * self.historical.loc[('QQQ')].close_price.astype(float).pct_change()[-1])\n",
        "\n",
        "    def change(self):\n",
        "        return (self.historical.loc[('QQQ')].close_price.astype(float)[-1] - self.historical.loc[('QQQ')].close_price.astype(float)[-2]) * self.shares\n",
        "\n",
        "    def yearly_pct(self):\n",
        "        return ((self.historical.loc[('QQQ')].close_price.astype(float)[-1] - self.historical.loc[('QQQ')].close_price.astype(float)[0]) / self.historical.loc[('QQQ')].close_price.astype(float)[0]) * 100\n",
        "\n",
        "    def yearly(self):\n",
        "        return (self.historical.loc[('QQQ')].close_price.astype(float)[-1] - self.historical.loc[('QQQ')].close_price.astype(float)[0]) * self.shares\n",
        "\n",
        "    def max_dollar(self):\n",
        "        return self.historical.loc[('QQQ')].close_price.astype(float).max() * self.shares\n",
        "\n",
        "    def min_dollar(self):\n",
        "        return self.historical.loc[('QQQ')].close_price.astype(float).min() * self.shares\n",
        "\n",
        "    def current_value(self):\n",
        "        return self.historical.loc[('QQQ')].close_price.astype(float)[-1] * self.shares\n",
        "\n",
        "    # print out some useful portfolio information\n",
        "    def summary(self):\n",
        "        print('Percent Change: %s' % (self.pct_change()))\n",
        "        print('Dollar Change: %s' % (self.change()))\n",
        "        print('Yearly Percent Change: %s' % (self.yearly_pct()))\n",
        "        print('Yearly Dollar Change: %s' % (self.yearly()))\n",
        "        print('Maximum: %s' % (self.max_dollar()))\n",
        "        print('Minimum: %s' % (self.min_dollar()))\n",
        "        print('Current Value: %s' % (self.current_value()))\n",
        "\n",
        "    # plot 1 year portfolio values\n",
        "    def one_year(self):\n",
        "        from matplotlib import pyplot as plt\n",
        "        import seaborn as sns\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        from matplotlib import pyplot as plt\n",
        "        import seaborn as sns\n",
        "\n",
        "        sns.set_palette('pastel')\n",
        "        sns.set_style('ticks')\n",
        "        sns.set_context('talk')\n",
        "\n",
        "        temp = self.historical.loc[('QQQ')].copy().reset_index().rename(columns={'begins_at':'Date'})\n",
        "        temp['Value'] = temp.close_price.astype(float) * self.shares\n",
        "\n",
        "        plt.figure() # start a figure\n",
        "        sns.lineplot(x='Date', y='Value', data=temp, color='#bea3ff')\n",
        "        sns.despine(offset=10, trim=True)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.title('1 Year Portfolio Value\\n')\n",
        "\n",
        "# uses live data to build a quote\n",
        "class Quote:\n",
        "    def __init__(self, symbol):\n",
        "        import pandas as pd\n",
        "        import urllib, re, json\n",
        "\n",
        "        self.symbol = symbol\n",
        "        self.web_data = json.loads(urllib.request.urlopen('https://api.robinhood.com/quotes/?symbols=%s' % (symbol)).read())['results'][0]\n",
        "\n",
        "        self.holdings = pd.read_csv('../personal_data/holdings.csv')\n",
        "        self.shares = float(self.holdings[self.holdings.Stock == symbol].Shares)\n",
        "\n",
        "    def ask_price(self):\n",
        "        return self.web_data['ask_price']\n",
        "\n",
        "    def ask_size(self):\n",
        "        return self.web_data['ask_size']\n",
        "\n",
        "    def bid_price(self):\n",
        "        return self.web_data['bid_price']\n",
        "\n",
        "    def bid_size(self):\n",
        "        return self.web_data['bid_size']\n",
        "\n",
        "    def last_trade_price(self):\n",
        "        return self.web_data['last_trade_price']\n",
        "\n",
        "    def last_extended_hours_trade_price(self):\n",
        "        import numpy as np\n",
        "\n",
        "        if self.web_data['last_extended_hours_trade_price']:\n",
        "            return self.web_data['last_extended_hours_trade_price']\n",
        "        else:\n",
        "            return np.nan\n",
        "\n",
        "    def previous_close(self):\n",
        "        return self.web_data['previous_close']\n",
        "\n",
        "    def adjusted_previous_close(self):\n",
        "        return self.web_data['adjusted_previous_close']\n",
        "\n",
        "    def previous_close_date(self):\n",
        "        return self.web_data['previous_close_date']\n",
        "\n",
        "    def trading_halted(self):\n",
        "        return self.web_data['trading_halted']\n",
        "\n",
        "    def has_traded(self):\n",
        "        return self.web_data['has_traded']\n",
        "\n",
        "    def last_trade_price_source(self):\n",
        "        return self.web_data['last_trade_price_source']\n",
        "\n",
        "    def percent_change(self):\n",
        "        return (((float(self.web_data['last_trade_price']) - float(self.web_data['previous_close'])) / float(self.web_data['previous_close']) * 100))\n",
        "\n",
        "    def percent_change_extended(self):\n",
        "        import numpy as np\n",
        "\n",
        "        if self.web_data['last_extended_hours_trade_price']:\n",
        "            return (((float(self.web_data['last_extended_hours_trade_price']) - float(self.web_data['last_trade_price'])) / float(self.web_data['last_trade_price']) * 100))\n",
        "        else:\n",
        "            return np.nan\n",
        "\n",
        "    def dollar_change(self):\n",
        "        return self.shares * self.percent_change()\n",
        "\n",
        "    def dollar_change_extended(self):\n",
        "        import numpy as np\n",
        "\n",
        "        if self.web_data['last_extended_hours_trade_price']:\n",
        "            return self.shares * self.percent_change_extended()\n",
        "        else:\n",
        "            return np.nan\n",
        "\n",
        "    # displays a general quote summary\n",
        "    def summary(self):\n",
        "        print('Previous Close: %s' % (self.previous_close()))\n",
        "        print('Last Trade Price: %s' % (self.last_trade_price()))\n",
        "        print('Last Trade Extended: %s' % (self.last_extended_hours_trade_price()))\n",
        "        print('Percent Change: %s' % (self.percent_change()))\n",
        "        print('Percent Change Extended: %s' % (self.percent_change_extended()))\n",
        "        print('Dollar Change: %s' % (self.dollar_change()))\n",
        "        print('Dollar Change Extended: %s' % (self.dollar_change_extended()))\n",
        "\n",
        "# gets a list of all symbols listed on the nasdaq\n",
        "def get_nasdaq_symbols(use_old=True):\n",
        "\n",
        "    # use a previous symbol list\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open('../data/nasdaq_symbols.pkl', 'rb')\n",
        "        symbols = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        import pandas_datareader.data as web\n",
        "        from pandas_datareader.nasdaq_trader import get_nasdaq_symbols\n",
        "        from datetime import date\n",
        "\n",
        "        # get current list of all nasdaq symbols\n",
        "        symbols = get_nasdaq_symbols()\n",
        "\n",
        "        # create file that will be accessed by current code\n",
        "        import pickle\n",
        "        p = open('../data/nasdaq_symbols.pkl', 'wb')\n",
        "        pickle.dump(symbols, p)\n",
        "        p.close()\n",
        "\n",
        "        # also create a backup as the symbols are updated daily\n",
        "        # and historical data is not available from nasdaq\n",
        "        p = open('../data/nasdaq_symbols_%s%s%s.pkl' % (date.today().day,\\\n",
        "                                                  date.today().month,\\\n",
        "                                                  date.today().year)\n",
        "                 , 'wb')\n",
        "        pickle.dump(symbols, p)\n",
        "        p.close()\n",
        "\n",
        "    return symbols\n",
        "\n",
        "# aggreataes 30yr of EOD data for all stocks listed in symbols\n",
        "def build_personal_database(symbols, use_old=True):\n",
        "\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open('../data/all_data.pkl', 'rb')\n",
        "        all_data = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        import pandas_datareader as web\n",
        "        import datetime\n",
        "        import pandas as pd\n",
        "\n",
        "        # get 30 years of data if available\n",
        "        end = datetime.datetime.today()\n",
        "        start = datetime.date(end.year-30,1,1)\n",
        "\n",
        "        all_data = pd.DataFrame()\n",
        "\n",
        "        for symbol in symbols.index:\n",
        "            try:\n",
        "                df = web.DataReader(symbol, 'yahoo', start, end)\n",
        "                df['Symbol'] = symbol\n",
        "                df = df.reset_index()\n",
        "                all_data = all_data.append(df, ignore_index=True)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        import pickle\n",
        "        p = open('all_data.pkl', 'wb')\n",
        "        pickle.dump(all_data, p)\n",
        "        p.close()\n",
        "\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# adds a number of calculations that can be used for machine learning\n",
        "def classify(all_data, use_old=True):\n",
        "\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open('../data/classified_data.pkl', 'rb')\n",
        "        all_data = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        # there is a bug that sometime prevents this first method from functioning as expected\n",
        "        # all_data['Pct_Change'] = all_data.groupby('Symbol', sort=False)['Adj Close'].pct_change()\n",
        "        all_data['Pct_Change'] = all_data.groupby('Symbol', sort=False)['Adj Close'].apply(lambda x: x.pct_change())\n",
        "\n",
        "        # shift is used to move the data up or down by row\n",
        "        # this classifies all recent EOD changes as either pos or neg\n",
        "        all_data['Up_1d'] = all_data.groupby('Symbol').Pct_Change.shift(1) > 0\n",
        "        all_data['Up_2d'] = all_data.groupby('Symbol').Pct_Change.shift(2) > 0\n",
        "        all_data['Up_3d'] = all_data.groupby('Symbol').Pct_Change.shift(3) > 0\n",
        "        all_data['Up_4d'] = all_data.groupby('Symbol').Pct_Change.shift(4) > 0\n",
        "        all_data['Up_5d'] = all_data.groupby('Symbol').Pct_Change.shift(5) > 0\n",
        "\n",
        "        # classifies the desired purchase stocks and dates\n",
        "        # between 3-4% change is about 2.9% of all EOD data\n",
        "        all_data['Purchase'] = ((all_data.groupby('Symbol').Pct_Change.shift(-1) > 0.03) & (all_data.groupby('Symbol').Pct_Change.shift(-1) < 0.04))\n",
        "\n",
        "        # classifies if total price movement is up or down over period of time\n",
        "        # the formula returns the total change in price over a course of time with 1 being no change\n",
        "        # explanation here: https://math.stackexchange.com/questions/3062312/calculate-total-percent-change-from-incremental-changes\n",
        "        pct_change = 1\n",
        "        for i in range(3):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_3d'] = pct_change\n",
        "        all_data.Tot_Up_3d = all_data.Tot_Up_3d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(5):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_5d'] = pct_change\n",
        "        all_data.Tot_Up_5d = all_data.Tot_Up_5d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(10):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_10d'] = pct_change\n",
        "        all_data.Tot_Up_10d = all_data.Tot_Up_10d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(15):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_15d'] = pct_change\n",
        "        all_data.Tot_Up_15d = all_data.Tot_Up_15d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(30):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_30d'] = pct_change\n",
        "        all_data.Tot_Up_30d = all_data.Tot_Up_30d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        # save classified data\n",
        "        import pickle\n",
        "        p = open('classified_data.pkl', 'wb')\n",
        "        pickle.dump(all_data, p)\n",
        "        p.close()\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# converts to 1/0 format that is usable by machine learning algorithm\n",
        "def convert(all_data, use_old=True):\n",
        "    # useful trick that converting to int will convert bool to 1/0\n",
        "    all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Purchase','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']] = \\\n",
        "    all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Purchase','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']].astype(int)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# this provides more exhaustive classification\n",
        "def new_classify(all_data, use_old=True):\n",
        "\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open('../data/classified_data.pkl', 'rb')\n",
        "        all_data = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        # there is a bug that sometime prevents this first method from functioning as expected\n",
        "        # all_data['Pct_Change'] = all_data.groupby('Symbol', sort=False)['Adj Close'].pct_change()\n",
        "        all_data['Pct_Change'] = all_data.groupby('Symbol', sort=False)['Adj Close'].apply(lambda x: x.pct_change())\n",
        "\n",
        "        # shift is used to move the data up or down by row\n",
        "        # this classifies all recent EOD changes as either pos or neg for 30 days prior to current day\n",
        "        for i in range(1,31):\n",
        "            all_data['Up_%id' % (i)] = all_data.groupby('Symbol').Pct_Change.shift(i) > 0\n",
        "\n",
        "        # classifies data by how the following day performs\n",
        "        # between 3-4% change is about 2.9% of all EOD data\n",
        "        all_data['Purchase'] = ((all_data.groupby('Symbol').Pct_Change.shift(-1) > 0.03) & (all_data.groupby('Symbol').Pct_Change.shift(-1) < 0.04))\n",
        "\n",
        "        # classifies if total price movement is up or down over period of time\n",
        "        # the formula returns the total change in price over a course of time with 1 being no change\n",
        "        # explanation here: https://math.stackexchange.com/questions/3062312/calculate-total-percent-change-from-incremental-changes\n",
        "        for i in range(1,31):\n",
        "            pct_change = 1\n",
        "            for i in range(i):\n",
        "                pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "            all_data['Tot_Up_%id' % (i)] = pct_change\n",
        "            all_data['Tot_Up_%id' % (i)] = all_data['Tot_Up_%id' % (i)] > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        # save classified data\n",
        "        import pickle\n",
        "        p = open('classified_data.pkl', 'wb')\n",
        "        pickle.dump(all_data, p)\n",
        "        p.close()\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# converts to 1/0 format that is usable by machine learning algorithm\n",
        "def new_convert(all_data, use_old=True):\n",
        "    # useful trick that converting to int will convert bool to 1/0\n",
        "    all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Purchase','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']] = \\\n",
        "    all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Purchase','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']].astype(int)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "sym_loc = '/content/drive/My Drive/Finance/turbospoon/data/nasdaq_symbols.pkl'\n",
        "# gets a list of all symbols listed on the nasdaq\n",
        "def get_nasdaq_symbols(loc=sym_loc, use_old=True):\n",
        "\n",
        "    # use a previous symbol list\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open(loc, 'rb')\n",
        "        symbols = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        import pandas_datareader.data as web\n",
        "        from pandas_datareader.nasdaq_trader import get_nasdaq_symbols\n",
        "        from datetime import date\n",
        "\n",
        "        # get current list of all nasdaq symbols\n",
        "        symbols = get_nasdaq_symbols()\n",
        "\n",
        "        # create file that will be accessed by current code\n",
        "        import pickle\n",
        "        p = open('../data/nasdaq_symbols.pkl', 'wb')\n",
        "        pickle.dump(symbols, p)\n",
        "        p.close()\n",
        "\n",
        "        # also create a backup as the symbols are updated daily\n",
        "        # and historical data is not available from nasdaq\n",
        "        p = open('../data/nasdaq_symbols_%s%s%s.pkl' % (date.today().day,\\\n",
        "                                                  date.today().month,\\\n",
        "                                                  date.today().year)\n",
        "                 , 'wb')\n",
        "        pickle.dump(symbols, p)\n",
        "        p.close()\n",
        "\n",
        "    return symbols\n",
        "\n",
        "# aggreataes 30yr of EOD data for all stocks listed in symbols\n",
        "def build_personal_database(symbols, data, use_old=True):\n",
        "\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open(data, 'rb')\n",
        "        all_data = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        import pandas_datareader as web\n",
        "        import datetime\n",
        "        import pandas as pd\n",
        "\n",
        "        # get 30 years of data if available\n",
        "        end = datetime.datetime.today()\n",
        "        start = datetime.date(end.year-30,1,1)\n",
        "\n",
        "        all_data = pd.DataFrame()\n",
        "\n",
        "        for symbol in symbols.index:\n",
        "            try:\n",
        "                df = web.DataReader(symbol, 'yahoo', start, end)\n",
        "                df['Symbol'] = symbol\n",
        "                df = df.reset_index()\n",
        "                all_data = all_data.append(df, ignore_index=True)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        import pickle\n",
        "        p = open('all_data.pkl', 'wb')\n",
        "        pickle.dump(all_data, p)\n",
        "        p.close()\n",
        "\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# adds a number of calculations that can be used for machine learning\n",
        "def classify(all_data, data, use_old=True):\n",
        "\n",
        "    if use_old:\n",
        "        import pickle\n",
        "        p = open(data, 'rb')\n",
        "        all_data = pickle.load(p)\n",
        "        p.close()\n",
        "\n",
        "    else:\n",
        "        # there is a bug that sometime prevents this first method from functioning as expected\n",
        "        # all_data['Pct_Change'] = all_data.groupby('Symbol', sort=False)['Adj Close'].pct_change()\n",
        "        all_data['Pct_Change'] = all_data.groupby('Symbol', sort=False)['Adj Close'].apply(lambda x: x.pct_change())\n",
        "\n",
        "        # shift is used to move the data up or down by row\n",
        "        # this classifies all recent EOD changes as either pos or neg\n",
        "        all_data['Up_1d'] = all_data.groupby('Symbol').Pct_Change.shift(1) > 0\n",
        "        all_data['Up_2d'] = all_data.groupby('Symbol').Pct_Change.shift(2) > 0\n",
        "        all_data['Up_3d'] = all_data.groupby('Symbol').Pct_Change.shift(3) > 0\n",
        "        all_data['Up_4d'] = all_data.groupby('Symbol').Pct_Change.shift(4) > 0\n",
        "        all_data['Up_5d'] = all_data.groupby('Symbol').Pct_Change.shift(5) > 0\n",
        "\n",
        "        # classifies the desired purchase stocks and dates\n",
        "        # between 3-4% change is about 2.9% of all EOD data\n",
        "        all_data['Purchase'] = ((all_data.groupby('Symbol').Pct_Change.shift(-1) > 0.03) & (all_data.groupby('Symbol').Pct_Change.shift(-1) < 0.04))\n",
        "\n",
        "        # classifies if total price movement is up or down over period of time\n",
        "        # the formula returns the total change in price over a course of time with 1 being no change\n",
        "        # explanation here: https://math.stackexchange.com/questions/3062312/calculate-total-percent-change-from-incremental-changes\n",
        "        pct_change = 1\n",
        "        for i in range(3):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_3d'] = pct_change\n",
        "        all_data.Tot_Up_3d = all_data.Tot_Up_3d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(5):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_5d'] = pct_change\n",
        "        all_data.Tot_Up_5d = all_data.Tot_Up_5d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(10):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_10d'] = pct_change\n",
        "        all_data.Tot_Up_10d = all_data.Tot_Up_10d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(15):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_15d'] = pct_change\n",
        "        all_data.Tot_Up_15d = all_data.Tot_Up_15d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        pct_change = 1\n",
        "        for i in range(30):\n",
        "            pct_change = pct_change * (1 + 1 * all_data.groupby('Symbol').Pct_Change.shift(i))\n",
        "        all_data['Tot_Up_30d'] = pct_change\n",
        "        all_data.Tot_Up_30d = all_data.Tot_Up_30d > 1 # if tot percent change > 1 set increase as True\n",
        "\n",
        "        # save classified data\n",
        "        import pickle\n",
        "        p = open('classified_data.pkl', 'wb')\n",
        "        pickle.dump(all_data, p)\n",
        "        p.close()\n",
        "\n",
        "    return all_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usdIvvLDwDb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get upgraded to a high RAM session\n",
        "def more_ram():\n",
        "    a = []\n",
        "    while(1):\n",
        "        a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9PHhdw0a420",
        "colab_type": "code",
        "outputId": "3bb49854-0db8-4840-9a35-bc68c2e3d267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1MdffGGLvsi",
        "colab_type": "text"
      },
      "source": [
        "# Get Historical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9XbwZJDLt9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get nasdaq symbols\n",
        "symbols = get_nasdaq_symbols(use_old=True)\n",
        "\n",
        "# build personal EOD database\n",
        "data = '/content/drive/My Drive/Finance/turbospoon/data/all_data.pkl'\n",
        "all_data = build_personal_database(symbols, data, use_old=True)\n",
        "\n",
        "# classify data\n",
        "data = '/content/drive/My Drive/Finance/turbospoon/data/classified_data.pkl'\n",
        "all_data = classify(all_data, data, use_old=True)\n",
        "\n",
        "# convert to dummy variables\n",
        "all_data = convert(all_data, use_old=True)\n",
        "#dummies = pd.get_dummies(all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXWkHWBAYwuB",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP6DxmSDYwuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf_train = clf.fit(all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']],\n",
        "                    all_data['Purchase'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8VOyo3eYwuI",
        "colab_type": "text"
      },
      "source": [
        "### Query Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTE7zEkmYwuJ",
        "colab_type": "code",
        "outputId": "b2d8677e-a35a-4968-b376-14ecff5c6df2",
        "colab": {}
      },
      "source": [
        "prediction = clf_train.predict([[0,0,0,1,1,0,0,1,1,1]])\n",
        "prediction[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2exhe_YYwuN",
        "colab_type": "text"
      },
      "source": [
        "### Test Model Usefulness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUYCkGfMYwuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction function\n",
        "#f = lambda x: clf_train.predict([[x.Up_1d, x.Up_2d, x.Up_3d, x.Up_4d, x.Up_5d, x.Tot_Up_3d, x.Tot_Up_5d, x.Tot_Up_10d, x.Tot_Up_15d, x.Tot_Up_30d]])[0]\n",
        "#temp['Prediction'] = temp.apply(f)\n",
        "'''\n",
        "temp['Prediction'] = clf_train.predict([[temp.Up_1d, temp.Up_2d, temp.Up_3d,\n",
        "                                           temp.Up_4d, temp.Up_5d, temp.Tot_Up_3d,\n",
        "                                           temp.Tot_Up_5d, temp.Tot_Up_10d, temp.Tot_Up_15d,\n",
        "                                           temp.Tot_Up_30d]])[0]\n",
        "                                           '''\n",
        "temp['Prediction'] = str(temp['Up_1d'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcH_UieNYwuR",
        "colab_type": "text"
      },
      "source": [
        "### Display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTuJoJqCYwuS",
        "colab_type": "code",
        "outputId": "772ad042-a7d1-4f9a-cba4-79acc1632a8f",
        "colab": {}
      },
      "source": [
        "dot_data = tree.export_graphviz(clf, filled=True, rounded=True)\n",
        "graph = graphviz.Source(dot_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'graphviz' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4854ca095588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'graphviz' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhmYKjz5YwuW",
        "colab_type": "text"
      },
      "source": [
        "### Todo\n",
        "Have a look at this:  \n",
        "`all_data[all_data.Symbol == 'AAPL'].tail(10)`  \n",
        "It does not seem that the classification of the Tot_Up_3d is correct on the 26th of December."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLbTxWfWYwuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data[['Up_1d','Up_2d','Up_3d','Up_4d','Up_5d','Tot_Up_3d','Tot_Up_5d','Tot_Up_10d','Tot_Up_15d','Tot_Up_30d']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUWG1hGMjglp",
        "colab_type": "code",
        "outputId": "89f0c2a1-0934-4b00-86b4-cee1afff3566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = 10000\n",
        "\n",
        "for i in range(3 * 365):\n",
        "    x = x * 1.01\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "539391740.5144053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y8e3Jgr_ena",
        "colab_type": "text"
      },
      "source": [
        "# KNN Clustering\n",
        "The first thing being done below is to see if there is any noticeable clustering of different classifications and `purchase` status."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLM_-HsX_kf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "c3eddb33-d3bd-473f-e3d1-e3a7b0308905"
      },
      "source": [
        "names = ['GOOG','AAPL','GE','SBUX','GS']\n",
        "dat = pd.DataFrame()\n",
        "purchase = pd.Series()\n",
        "\n",
        "for name in names:\n",
        "\n",
        "    dat = dat.append(all_data[all_data.Symbol == name][[\n",
        "                                                        'Up_1d','Up_2d','Up_3d','Up_4d','Up_5d',\n",
        "                                                        'Tot_Up_3d','Tot_Up_5d','Tot_Up_10d',\n",
        "                                                        'Tot_Up_15d','Tot_Up_30d']].head(5000).tail(4500),\n",
        "                     ignore_index=True)\n",
        "    purchase = purchase.append(all_data[all_data.Symbol == name].Purchase.head(5000).tail(4500),\n",
        "                               ignore_index=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dat, purchase, random_state=0)\n",
        "print(X_train[:5], y_train[:5])\n",
        "print(X_test[:5], y_test[:5])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "       Up_1d  Up_2d  Up_3d  ...  Tot_Up_10d  Tot_Up_15d  Tot_Up_30d\n",
            "4688       0      0      0  ...           0           0           0\n",
            "15715      0      1      1  ...           1           1           1\n",
            "12352      0      1      1  ...           1           1           1\n",
            "11582      0      0      1  ...           1           1           1\n",
            "16761      1      1      0  ...           1           1           1\n",
            "\n",
            "[5 rows x 10 columns] 4688     0\n",
            "15715    0\n",
            "12352    0\n",
            "11582    0\n",
            "16761    0\n",
            "dtype: int64\n",
            "       Up_1d  Up_2d  Up_3d  ...  Tot_Up_10d  Tot_Up_15d  Tot_Up_30d\n",
            "4808       0      0      0  ...           1           1           1\n",
            "19508      0      1      0  ...           0           0           1\n",
            "4309       0      1      0  ...           0           0           1\n",
            "2604       1      1      1  ...           0           0           0\n",
            "1783       1      1      0  ...           1           1           0\n",
            "\n",
            "[5 rows x 10 columns] 4808     0\n",
            "19508    0\n",
            "4309     0\n",
            "2604     0\n",
            "1783     0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3D8cw8mBtRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c712b508-d94e-4f4a-d670-8dcf62d31cd7"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-COEgo2D1z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "25cd479d-00fc-4243-d3ad-18d4e5dc863c"
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "#print(y_pred)\n",
        "#print(y_test)\n",
        "print(np.mean(y_pred == y_test))\n",
        "# print(knn.score(X_test, y_test))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "0.9385640266469282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9t-gN4EYhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = pd.Series(y_pred)\n",
        "y_test = pd.Series(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDi-crhnLxjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}